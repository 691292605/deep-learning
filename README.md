实践二利用实践一结合ppt的内容建立的简单BP神经网络对mnist数据集进行了训练，通过调整隐藏层参数，学习率，激活函数以及训练次数后可以将模型的正确率达到94%多接近95%

实践三通过使用pytorch来搭建简单的神经网络进行mnist数据集的训练，且损失函数均采用交叉熵损失函数，优化器采用Adam优化器
1，lenet模型结构：
Conv1 输入通道为1，输出通道为6，卷积核大小为5，池化层大小为2，采用“same padding”
激活函数采用Relu函数
pool采用最大池化
Conv2 输入通道为6，输出通道为16，卷积核大小为5，池化层大小为2，采用“same padding”
将数据展平后通过两次Relu函数作用以及线性变换得到最终的output
经过合适的参数训练后模型的准确率可以达到99%
2，vgg模型：
由于vgg模型的网络深度较深以及mnist数据集图像大小较小，因此这里采用了较为简化的vgg模型对mnist数据集进行训练
模型结构：
conv1 输入通道为1，输出通道为32，卷积核大小为5，池化层大小为2，采用“same padding”
池化层采用最大池化并进行归一化
conv2 输入通道为32，输出通道为64，卷积核大小为5，池化层大小为2，采用“same padding”
池化层采用最大池化并进行归一化
将数据展平后经过线性变换，Relu函数作用，dropout层，线性变换后得到最终的output
经过合适的参数训练后模型的准确率可以达到98%接近99%
3，resent-18模型
通过调取resent函数进行训练，最终的准确率可以达到99%
4，ViT网络结构：
将图片转换为patches序列：将图形经过卷积计算进行分块，其中输入通道为1，输出通道为embedding_size，卷积核大小为patch_size，步长为patch_size，在此模型中，patch_size为7，embedding_size为256
将patches铺平并添加绝对位置编码
添加class_token
将数据输入transformer中再进行线性变换得到最终的output
