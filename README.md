# 实践二
利用实践一结合ppt的内容建立的简单BP神经网络对mnist数据集进行了训练，通过调整隐藏层参数，学习率，激活函数以及训练次数后可以将模型的正确率达到94%多接近95%
# 实践三
通过使用pytorch来搭建简单的神经网络进行mnist数据集的训练，且损失函数均采用交叉熵损失函数，优化器采用Adam优化器
## lenet模型：
- Conv1 输入通道为1，输出通道为6，卷积核大小为5，池化层大小为2，采用“same padding”
- 激活函数采用Relu函数
- pool采用最大池化
- Conv2 输入通道为6，输出通道为16，卷积核大小为5，池化层大小为2，采用“same padding”
- 将数据展平后通过两次Relu函数作用以及线性变换得到最终的output，经过合适的参数训练后模型的准确率可以接近99%
## vgg模型：
由于vgg模型的网络深度较深以及mnist数据集图像大小较小，因此这里采用了较为简化的vgg模型对mnist数据集进行训练
模型结构：
- conv1 输入通道为1，输出通道为32，卷积核大小为5，池化层大小为2，采用“same padding”
- 池化层采用最大池化并进行归一化
- conv2 输入通道为32，输出通道为64，卷积核大小为5，池化层大小为2，采用“same padding”
- 池化层采用最大池化并进行归一化
- 将数据展平后经过线性变换，Relu函数作用，dropout层，线性变换后得到最终的output，经过合适的参数训练后模型的准确率可以达到98%接近99%
## resent-18模型
通过调取resent函数进行训练，最终的准确率可以达到98%，接近99%
## ViT网络：
- 将图片转换为patches序列：将图形经过卷积计算进行分块，其中输入通道为1，输出通道为embedding_size，卷积核大小为patch_size，步长为patch_size，在此模型中，patch_size为7，embedding_size为256
- 将patches铺平并添加绝对位置编码
- 添加class_token
- 将数据输入transformer中再进行线性变换得到最终的output，经过训练后该网络的准确率可以达到94%左右
# 实践四
- 通过分析图像的掩膜发现其掩膜矩阵中的非零元素代表着其中的物体所属的类别，因此在进行训练时先对数据集中图像的进行处理，通过get_classes函数来提取其中的类别来得到标签矩阵
- 由于label中的类别不止一种，因此需要更改获得预测正确得样本的个数的方法，这里采用对输出向量和label向量进行逐项比较，即通过对output和label和一个小量t进行的比较来判断是否预测正确，具体功能由函数evaluate实现
- 得到了label矩阵后则同于实践三进行训练即可，唯一不同的是将损失函数改为了均方误差函数，经过训练后发现lenet，vgg，resnet-18，vit的准确率均可达到100%
